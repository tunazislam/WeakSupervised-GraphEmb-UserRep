{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p  #pip install tweet-preprocessor\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation as punc\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.models as gsm\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import regex\n",
    "import emoji #pip install emoji --upgrade\n",
    "# Internal dependencies\n",
    "#import word_emoji2vec as we2v\n",
    "#from word_emoji2vec import Word_Emoji2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "###word cloud\n",
    "#!pip install wordcloud\n",
    "from wordcloud import WordCloud \n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "from apex.parallel import DistributedDataParallel as DDP \n",
    "from apex import amp\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1, 2, 3' \n",
    "#....to install apex...\n",
    "#pip install -v --no-cache-dir ./\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed #python -m spacy download en\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "np.random.seed(1)\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd \n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('data/keto/graph_embd_keto/output/des_only/user_des.embeddings', sep=\"\\t\", names=[\"user\", \"vector\"], index_col=0)\n",
    "input_dic = {key: val.values for key, val in df.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split vectors based on space and convert to list\n",
    "split_vector = []\n",
    "for i in range (0, df.shape[0]):\n",
    "    split_vector.append(df.vector[i].split(' '))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(split_vector), split_vector[0]\n",
    "split_vector[0][0], type(split_vector[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert an array of strings to an array of floats in numpy?\n",
    "\n",
    "np_split_vector = np.array(split_vector)\n",
    "emb = np_split_vector.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(emb[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic = {}\n",
    "\n",
    "for i in range (0,len(emb)):\n",
    "    for k in input_dic:\n",
    "        if k not in user_dic:\n",
    "            user_dic[k] = emb[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the predicted data\n",
    "predicted_df = pd.read_csv( 'data/keto/predicted_keto_14k.csv',low_memory=False) #(28189, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_q = predicted_df[['name',  'utype_gt']] #extracted 2 columns\n",
    "#print(df_q)\n",
    "df_q1= df_q.dropna()#dropping nan value\n",
    "#print(df_q1) #1300\n",
    "df_q1 = df_q1[df_q1.utype_gt != 2.0] #dropping rows with truth value 2.0\n",
    "df_q1 = df_q1.reset_index(drop = True)\n",
    "print(df_q1) #908\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "#     for word in model.wv.vocab:\n",
    "#         tokens.append(model[word])\n",
    "#         labels.append(word)\n",
    "#     for k, v in user_dic.items():\n",
    "#         if k in df_q1.name:\n",
    "#             tokens.append(v)\n",
    "#             #labels.append(k)\n",
    "#             labels.append(df_q1.utype_gt[])\n",
    "        \n",
    "    for k, v in user_dic.items():\n",
    "        if k in df_q1.name.values:\n",
    "            #print(k)\n",
    "            tokens.append(v)\n",
    "            #labels.append(df_q1.loc[(df_q1['name'] == k)].utype_gt.values)\n",
    "            lb = (df_q1.loc[(df_q1['name'] == k)].utype_gt.values)\n",
    "            if lb[0] == 0:\n",
    "                labels.append('Practitioner')\n",
    "            if lb[0] == 1:\n",
    "                labels.append('Promotional')\n",
    "                \n",
    "        \n",
    "    #tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    tsne_model = TSNE(perplexity=50, n_components=2, init='pca', n_iter=2500, learning_rate = 200, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "    #print(labels) #array([1.]), array([1.])]\n",
    "#     print('x', min(x),max(x))\n",
    "#     print('y', min(y), max(y))\n",
    "\n",
    "    plt.figure(figsize=(6, 6)) \n",
    "    \n",
    "#     plt.xlim(-10, 10)\n",
    "#     plt.ylim(-80, 50)\n",
    "    import matplotlib\n",
    "    classes = ['Practitioner', 'Promotional']\n",
    "    #colors = ['green','red']\n",
    "    #plt.scatter(x,y, c = labels , cmap= matplotlib.colors.ListedColormap(colors))\n",
    "    import seaborn as sns\n",
    "    sns.scatterplot(x=x, y=y, hue=labels)\n",
    "    #plt.show()\n",
    "    plt.savefig('data/keto/embedding_plot/graph_learn_keto.png')\n",
    "tsne_plot(user_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
